{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pruning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsel/Pruning-the-Neural-Networks/blob/master/Pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orI6QVDbcejv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Purning**\n",
        "Pruning is one of the methods for inference to efficiently produce models smaller in size, more memory-efficient, more power-efficient and faster at inference with minimal loss in accuracy, other such techniques being weight sharing and quantization. Out of several aspects that deep learning takes as an inspiration from the area of Neuroscience. Pruning in deep learning is also a biologically inspired.\n",
        "\n",
        "## Purning helps to solve the problems of:\n",
        "1) Model are getting larger<br>\n",
        "2) Speed of the machine if you use CPU<br>\n",
        "3) Energy Efficiency (Memory Usage)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfW6QAL4sEPy",
        "colab_type": "text"
      },
      "source": [
        "## Setup the notebook (for Colab)\n",
        "\n",
        "**Enable the GPU with**: Runtime > Change runtime type > Hardware accelator and make sure GPU is selected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-AxgUFRZYF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for tensorboard in google colab\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFClMhg_fBPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the required libraries \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime, os\n",
        "import tempfile\n",
        "from shutil import copyfile,move \n",
        "import h5py\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import glob\n",
        "from numpy import linalg as LA\n",
        "from scipy.stats import rankdata\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwtf-I7NlP8A",
        "colab_type": "code",
        "outputId": "dfed7151-5b5a-420e-bb8f-6d413e9f4aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "#Data Preprocessing\n",
        "#download the MNIST datasets from keras.datasets.mnist\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_data = train_data.reshape(train_data.shape[0], img_rows*img_cols)\n",
        "test_data = test_data.reshape(test_data.shape[0], img_rows* img_cols)\n",
        "input_shape = (img_rows* img_cols, )\n",
        "\n",
        "\n",
        "train_data = train_data.astype('float32')\n",
        "test_data = test_data.astype('float32')\n",
        "train_data /= 255\n",
        "test_data /= 255\n",
        "print('train_data shape:', train_data.shape)\n",
        "print(train_data.shape[0], 'train samples')\n",
        "print(test_data.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "print(\"num_classes:\", num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data shape: (60000, 784)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "num_classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzxlPR_nqLbq",
        "colab_type": "text"
      },
      "source": [
        "## Before the Puring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buQTNK9IfHvq",
        "colab_type": "code",
        "outputId": "45202ed9-c08f-44db-852c-64d5cf286912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "#creating the Simple Neural Networks without using CNN\n",
        "\n",
        "#input size 784\n",
        "#activation function for Networks: ReLu function\n",
        "#for the final output layer we use Softmax activation function\n",
        "\n",
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1000,input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1000,activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(500,activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(200,activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(num_classes,activation=tf.nn.softmax)\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200)               100200    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 2,388,710\n",
            "Trainable params: 2,388,710\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsnbDg3WlI9k",
        "colab_type": "code",
        "outputId": "0e295bdb-06da-47ca-9b53-822357b914de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "#for tensorboard usage\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "#compling the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, train_labels,\n",
        "          batch_size=batch_size,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          callbacks=[tensorboard_callback],\n",
        "          validation_data=(test_data, test_labels))\n",
        "\n",
        "score = model.evaluate(test_data, test_labels, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 29s 488us/sample - loss: 0.2173 - accuracy: 0.9335 - val_loss: 0.1172 - val_accuracy: 0.9627\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 28s 462us/sample - loss: 0.1022 - accuracy: 0.9694 - val_loss: 0.1008 - val_accuracy: 0.9703\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 28s 470us/sample - loss: 0.0833 - accuracy: 0.9753 - val_loss: 0.0913 - val_accuracy: 0.9709\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 27s 443us/sample - loss: 0.0665 - accuracy: 0.9797 - val_loss: 0.0805 - val_accuracy: 0.9761\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 27s 454us/sample - loss: 0.0616 - accuracy: 0.9816 - val_loss: 0.1031 - val_accuracy: 0.9720\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 28s 466us/sample - loss: 0.0481 - accuracy: 0.9849 - val_loss: 0.1022 - val_accuracy: 0.9713\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 28s 471us/sample - loss: 0.0460 - accuracy: 0.9857 - val_loss: 0.0833 - val_accuracy: 0.9774\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 27s 443us/sample - loss: 0.0393 - accuracy: 0.9876 - val_loss: 0.0754 - val_accuracy: 0.9802\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 27s 458us/sample - loss: 0.0382 - accuracy: 0.9888 - val_loss: 0.0884 - val_accuracy: 0.9786\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 29s 481us/sample - loss: 0.0375 - accuracy: 0.9885 - val_loss: 0.0956 - val_accuracy: 0.9755\n",
            "Test loss: 0.09559270722349966\n",
            "Test accuracy: 0.9755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klvf8KFHly6i",
        "colab_type": "code",
        "outputId": "14c9b7d4-e31e-4f35-da5d-7c4e0ce1cc96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 628), started 2:18:44 ago. (Use '!kill 628' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF-lFQhJ0Pwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save model\n",
        "_, model_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, model_file, include_optimizer=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8vqawzWrtNr",
        "colab_type": "text"
      },
      "source": [
        "## **Here we are comparing two different Purning techniques<br> <br>**\n",
        "1) **Weight Pruning** <br> \n",
        "2) **Unit/Neuron Pruning**\n",
        "\n",
        "#### Weight pruning\n",
        "1)Set individual weights in the weight matrix to zero. This corresponds to deleting connections.<br>\n",
        "\n",
        "2)Here, to achieve *sparsity* of k% we rank the individual weights in weight matrix W according to their magnitude, and then set to zero the smallest k%.\n",
        "\n",
        "Tensors with several values set to zero can be considered *sparse*. This results in important benefits:\n",
        "* *Compression*. Sparse tensors are amenable to compression by only keeping the non-zero values and their corresponding coordinates.\n",
        "* *Speed*. Sparse tensors allow us to skip otherwise unnecessary computations involving the zero values.\n",
        "\n",
        "#### Unit/Neuron Pruning\n",
        "1)Set entire columns to zero in the weight matrix to zero, in effect deleting the corresponding output neuron.<br>\n",
        "\n",
        "2)Here to achieve *sparsity* of k% we rank the columns of a weight matrix according to their *L2-norm* and delete the smallest k%.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En5Yyi6hrpvT",
        "colab_type": "text"
      },
      "source": [
        "### Weight Purning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faKpi7eVp6SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prune away(set to zero) the k% of weights using weight pruning for k in [0, 25, 50, 60, 70, 80, 90, 95, 97, 99]\n",
        "for k in [.0 ,.25, .50, .60, .70, .80, .90, .95, .97, .99]:\n",
        "  copyfile(model_file,\"/tmp/orig.h5\")\n",
        "  f = h5py.File(\"/tmp/orig.h5\",'r+')\n",
        "  ranks = {}\n",
        "  for l in list(f['model_weights'])[:-1]:\n",
        "#   for l in ['dense', 'dense_1', 'dense_2', 'dense_3']:\n",
        "    data = f['model_weights'][l][l]['kernel:0']\n",
        "    w = np.array(data)\n",
        "    ranks[l]=(rankdata(np.abs(w),method='dense') - 1).astype(int).reshape(w.shape)\n",
        "    lower_bound_rank = np.ceil(np.max(ranks[l])*k).astype(int)\n",
        "    ranks[l][ranks[l]<=lower_bound_rank] = 0\n",
        "    ranks[l][ranks[l]>lower_bound_rank] = 1\n",
        "    w = w*ranks[l]\n",
        "    data[...] = w\n",
        "  f.close()\n",
        "  move(\"/tmp/orig.h5\",\"/tmp/weight_\"+str(k)+\".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjZTmY5j4aF4",
        "colab_type": "text"
      },
      "source": [
        "### Unit/Neuron Purning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9w4phYe4dxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prune away(set to zero) the k% of weights using Unit/Neuron pruning for k in [0, 25, 50, 60, 70, 80, 90, 95, 97, 99]\n",
        "for k in [.0, .25, .50, .60, .70, .80, .90, .95, .97, .99]:\n",
        "  copyfile(model_file,\"/tmp/orig.h5\")\n",
        "  f = h5py.File(\"/tmp/orig.h5\",'r+')\n",
        "  ranks = {}\n",
        "  for l in list(f['model_weights'])[:-1]:\n",
        "#   for l in ['dense', 'dense_1', 'dense_2', 'dense_3']:\n",
        "    data = f['model_weights'][l][l]['kernel:0']\n",
        "    w = np.array(data)\n",
        "    norm = LA.norm(w,axis=0)\n",
        "    norm = np.tile(norm,(w.shape[0],1))\n",
        "    ranks[l] = (rankdata(norm,method='dense') - 1).astype(int).reshape(norm.shape)\n",
        "    lower_bound_rank = np.ceil(np.max(ranks[l])*k).astype(int)\n",
        "    ranks[l][ranks[l]<=lower_bound_rank] = 0\n",
        "    ranks[l][ranks[l]>lower_bound_rank] = 1\n",
        "    w = w*ranks[l]\n",
        "    data[...] = w\n",
        "  f.close()\n",
        "  move(\"/tmp/orig.h5\",\"/tmp/neuron\"+str(k)+\".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNYoyVxY5UzS",
        "colab_type": "code",
        "outputId": "7f91664f-3048-4471-d7b8-97e06da1e0b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "#we can check the decreasing in the accuracy while droping down the parameters\n",
        "\n",
        "files_weights = glob.glob('/tmp/weight*.h5')\n",
        "files_weights.sort()\n",
        "files_neuron = glob.glob('/tmp/neuron*.h5')\n",
        "files_neuron.sort()\n",
        "  \n",
        "accuracy_weights = []\n",
        "accuracy_neurons = []\n",
        "\n",
        "for f in files_weights:\n",
        "  restored_model = tf.keras.models.load_model(f,compile=False)\n",
        "  restored_model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "  score = restored_model.evaluate(test_data, test_labels, verbose=0)\n",
        "  fl = h5py.File(f)\n",
        "  params = 0\n",
        "  for l in list(fl['model_weights']):\n",
        "    val = np.array(fl['model_weights'][l][l]['kernel:0'])\n",
        "    params += val[val>0].shape[0]\n",
        "  accuracy_weights.append(score[1])\n",
        "  print('Params ',params)\n",
        "  print('Model ',f)\n",
        "  print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "for f in files_neuron:\n",
        "  restored_model = tf.keras.models.load_model(f,compile=False)\n",
        "  restored_model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "  score = restored_model.evaluate(test_data,test_labels, verbose=0)\n",
        "  fl = h5py.File(f)\n",
        "  params = 0\n",
        "  for l in list(fl['model_weights']):\n",
        "      val = np.array(fl['model_weights'][l][l]['kernel:0'])\n",
        "      params += val[val>0].shape[0]\n",
        "  accuracy_neurons.append(score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params  1137381\n",
            "Model  /tmp/weight_0.0.h5\n",
            "Test accuracy: 0.9755\n",
            "Params  843203\n",
            "Model  /tmp/weight_0.25.h5\n",
            "Test accuracy: 0.9753\n",
            "Params  551876\n",
            "Model  /tmp/weight_0.5.h5\n",
            "Test accuracy: 0.9753\n",
            "Params  437212\n",
            "Model  /tmp/weight_0.6.h5\n",
            "Test accuracy: 0.9751\n",
            "Params  324536\n",
            "Model  /tmp/weight_0.7.h5\n",
            "Test accuracy: 0.9721\n",
            "Params  213664\n",
            "Model  /tmp/weight_0.8.h5\n",
            "Test accuracy: 0.9559\n",
            "Params  104975\n",
            "Model  /tmp/weight_0.9.h5\n",
            "Test accuracy: 0.718\n",
            "Params  52362\n",
            "Model  /tmp/weight_0.95.h5\n",
            "Test accuracy: 0.114\n",
            "Params  31538\n",
            "Model  /tmp/weight_0.97.h5\n",
            "Test accuracy: 0.0974\n",
            "Params  10963\n",
            "Model  /tmp/weight_0.99.h5\n",
            "Test accuracy: 0.0974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d35yNghaIasE",
        "colab_type": "code",
        "outputId": "b38b8993-1533-488a-aa38-eba74754b414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Saving the Pruned model\n",
        "_, new_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving pruned model to: ', new_pruned_keras_file)\n",
        "tf.keras.models.save_model(restored_model, new_pruned_keras_file, \n",
        "                        include_optimizer=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving pruned model to:  /tmp/tmp2lmjqq48.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYU8S4Nv48cW",
        "colab_type": "code",
        "outputId": "b72cb06d-9cb7-4a85-f8b7-d090cf6d1248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "#plotting the graph between accuracy and sparsity of Weight Pruning and Unit Pruning\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "plt.rcParams['figure.constrained_layout.use'] = True\n",
        "plt.xlabel('% sparsity')\n",
        "plt.ylabel('% accuracy')\n",
        "red_patch = mpatches.Patch(color='red', label='Unit Pruning')\n",
        "blue_patch = mpatches.Patch(color='blue',label='Weight Pruning')\n",
        "plt.legend(handles=[red_patch,blue_patch],loc='upper right')\n",
        "plt.plot([.0, .25, .50, .60, .70, .80, .90, .95, .97, .99],accuracy_neurons,color='red')\n",
        "plt.plot([.0, .25, .50, .60, .70, .80, .90, .95, .97, .99],accuracy_weights,color='blue')\n",
        "plt.title(\"Curve Differ in Unit and Weight Pruning\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAEoCAYAAAAqrOTwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur6vm1n6HxN7",
        "colab_type": "code",
        "outputId": "e1629c2e-febe-47e5-ac7e-1a5953833a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "#Compare the size of the unpruned vs. pruned model after compression\n",
        "\n",
        "pruned_keras_files = files_neuron+files_weights\n",
        "\n",
        "\n",
        "for pruned_keras_file in pruned_keras_files:\n",
        "  _, zip2 = tempfile.mkstemp('.zip') \n",
        "  with zipfile.ZipFile(zip2, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(pruned_keras_file)\n",
        "  print(\"Size of the pruned model before compression: %.2f Mb\" % \n",
        "        (os.path.getsize(pruned_keras_file) / float(2**20)))\n",
        "  print(\"Size of the pruned model after compression: %.2f Mb\" % \n",
        "        (os.path.getsize(zip2) / float(2**20)))\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 8.44 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 7.08 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 5.29 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 4.51 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 3.67 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 2.76 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 1.78 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 1.25 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 1.02 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 0.76 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 8.44 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 6.97 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 5.13 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 4.36 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 3.54 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 2.68 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 1.75 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 1.23 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 1.01 Mb\n",
            "Size of the pruned model before compression: 9.13 Mb\n",
            "Size of the pruned model after compression: 0.77 Mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e5SXurnWrU2",
        "colab_type": "text"
      },
      "source": [
        "## Observation after this research\n",
        "### **Q) What intresting insights did you find?<br>**\n",
        "\n",
        "After this experiment of Pruning the networks I find that if we Pruned so much in the network then the accuracy drop will be incresed so fast as you can see the *decreasing in the accuracy while droping down the parameters* and also by pruned the networks its compressed the networks which helps in the optimise the space of system.\n",
        "Not only the saving the space but we can also use this to mobile device and trained on CPU too.\n",
        "\n",
        "### **Q) Do the curves differ?<br>**\n",
        "\n",
        "Yes, the curves between the *Weights Pruning and the Unit Pruning*, there has an curves different.<br>\n",
        "For **Unit Pruning**, the accuracy drop start after the *50% of sparsity* and ***around 60% to 80% sparsity*** the the accuracy drop is dramatically decreased. That's means the after the **50% of Sparsity the accuracy will drop down**<br>\n",
        "\n",
        "For **Weight Pruning**, the accuracy drop start after the ***85% of sparsity***<br>\n",
        "\n",
        "So from above observation, we can say that the more than 60% of sparisty in neural networks are not good for accuray\n",
        "\n",
        "### **Q) Do you have any hypotheses as to why we are able to delete so much of the network without hurting performance.<br>**\n",
        "\n",
        "I think because the features in neurons are repeating with each others, so by deleting the networks it does not effect the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vppdP5K9xDeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCMmxIoXNFPP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibeQJiCSVhJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}